{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFrcJGq49ZQU"
      },
      "outputs": [],
      "source": [
        "# import the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape =(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSPx3PeZCysS",
        "outputId": "c600e37b-cfb1-4230-a6a2-55462b76a92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# get the training and test set\n",
        "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
      ],
      "metadata": {
        "id": "qzMh2h_BGxbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a7461c-626b-4612-91c2-93b17b7996f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the training and test data\n",
        "train_images = train_images/255.0\n",
        "test_Images = test_images/255.0"
      ],
      "metadata": {
        "id": "20NBihsFF4ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Neural Network\n",
        "So in this case, using the training data, our\n",
        "model ended up with an accuracy of about 91.1% after only five epochs."
      ],
      "metadata": {
        "id": "NTPw01h6Q3VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit data\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs = 5, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD6im6vKOfy0",
        "outputId": "ed49c56a-f2bb-4a37-c84d-20f5bd6dfee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 10s - 6ms/step - accuracy: 0.8239 - loss: 0.5033\n",
            "Epoch 2/5\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.8639 - loss: 0.3791\n",
            "Epoch 3/5\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.8759 - loss: 0.3380\n",
            "Epoch 4/5\n",
            "1875/1875 - 10s - 6ms/step - accuracy: 0.8841 - loss: 0.3160\n",
            "Epoch 5/5\n",
            "1875/1875 - 18s - 10ms/step - accuracy: 0.8910 - loss: 0.2977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa21a11dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case the accuracy of the model was 87.77%, which isn’t bad considering we only trained it for five epochs.\n"
      ],
      "metadata": {
        "id": "57LoqispQ8OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on the test set\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Wx3RxlPSWJ",
        "outputId": "f6625b1a-d93e-4044-cefd-6c2c6acc63bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 56.2113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59.48931121826172, 0.8551999926567078]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Model Output\n",
        "Now that the model has been trained, and we have a good gage of its accuracy using the test set, let’s explore it a little:\n",
        "\n",
        "We’ll get a set of classifications by passing the test images to model.predict. Then\n",
        "let’s see what we get if we print out the first of the classifications and compare it to the test label"
      ],
      "metadata": {
        "id": "FYjcumo4TxYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass a set of test images to `model.predict`\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heno1iSpQxc2",
        "outputId": "1548b40e-459c-492c-f207-af085ca6635a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.99999994]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopping Training Using CallBacks\n",
        "we might want to train until we reach the desired accuracy instead of constantly trying different numbers of epochs and training and retraining until we get to our desired value. The easiest approach is to use a callback on the training."
      ],
      "metadata": {
        "id": "-LTSZlXk8PlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a call back to stop the training\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "JGcwkx4eVsHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels,\n",
        "          epochs = 50, callbacks = [callbacks], verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b4xkDMgfA4C",
        "outputId": "77748d8e-427f-4497-b04b-1818b07619ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2806\n",
            "Epoch 2/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2735\n",
            "Epoch 3/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2558\n",
            "Epoch 4/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2511\n",
            "Epoch 5/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2394\n",
            "Epoch 6/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2314\n",
            "Epoch 7/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 0.2268\n",
            "Epoch 8/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2210\n",
            "Epoch 9/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2109\n",
            "Epoch 10/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.2024\n",
            "Epoch 11/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2028\n",
            "Epoch 12/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.1907\n",
            "Epoch 13/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.1888\n",
            "Epoch 14/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.1787\n",
            "Epoch 15/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.1724\n",
            "Epoch 16/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1768\n",
            "Epoch 17/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.1705\n",
            "Epoch 18/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.1663\n",
            "Epoch 19/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1632\n",
            "Epoch 20/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.1574\n",
            "Epoch 21/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1571\n",
            "Epoch 22/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1499\n",
            "Epoch 23/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.1439\n",
            "Epoch 24/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1431\n",
            "Epoch 25/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1416\n",
            "Epoch 26/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1374\n",
            "Epoch 27/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1362\n",
            "Epoch 28/50\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1304\n",
            "Epoch 29/50\n",
            "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1283\n",
            "Reached 95% accuracy so cancelling training\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa215e9dea0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN with MNIST\n",
        "prior to normalizing the images, we also reshape each array to have that extra dimension. The following code changes our training dataset from 60,000 images, each 28 × 28 (and thus a 60,000 × 28 × 28 array), to 60,000 images, each 28 × 28 × 1:"
      ],
      "metadata": {
        "id": "EvAsVOuM67ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the training and test data\n",
        "train_images = train_images.reshape(60000, 28, 28,1)\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images.reshape(10000, 28, 28,1)\n",
        "test_Images = test_images/255.0"
      ],
      "metadata": {
        "id": "qsC_v6yf7Up_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',\n",
        "                           input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(input_shape =(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "qXAE-r9-iKmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}